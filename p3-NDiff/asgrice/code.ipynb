{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_5evX44xyk0"
   },
   "source": [
    "# Project 3 Numerical Differentiation and Machine Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb7jXFyKxyk4"
   },
   "source": [
    "Throughout physics, we need to be able to take derivatives of both functions and of data. However, as we will see below this process can introduce large errors, so we need to procede carefully (much more carefully than for integration!)\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "After this lesson, you should be able to:\n",
    "* Compute a numerical derivative using forward/backward differentiation\n",
    "* Be able to use different stencils\n",
    "* Compare two floating point numbers\n",
    "* Evaluate and communicate the numerical error resulting from performing differentiation discretely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwfS0z2sd6YO"
   },
   "source": [
    "# Pre-class\n",
    "\n",
    "Remind yourself of Taylor series, either through your calculus textbook and/or this [video](https://youtu.be/3d6DsjIBzJ4)\n",
    "\n",
    "Read Sec 3.2 of TAK. You will probably find it helpful to read along using a paper/pencil, and/or be able to draw on your PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9xuJ5qxd6YP"
   },
   "source": [
    "# In-class\n",
    "\n",
    "Today's class (1) requires that you carefully read and understand some mathematical derivations and (2) the in-class work is also the HW asignment (unlike usually...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiiQUx8wxyk5"
   },
   "source": [
    "## Derivatives\n",
    "\n",
    "Estimating the derivative of a function is a very common task in scientific computing. The need arises, for example, when \n",
    "we have data that represent some dependent variable $f$ as a function of an independent variable $x$, and we would like \n",
    "to know the rate at which $f$ changes. If the data are generated from a numerical code, or from an experiment, then $f$ is \n",
    "only known at discrete \n",
    "values of $x$ and we cannot differentiate $f(x)$ analytically. We must resort to numerical techniques. \n",
    "\n",
    "Numerical differentiation can be difficult to do well. We cannot apply the definition \n",
    "\n",
    "$$\n",
    "f'(x)  = \\lim_{h\\to 0}\\frac{f(x+h)-f(x)}{h} \n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "directly if the data are discrete, because we cannot take the limit $h\\to 0$. Even in cases where we can evaluate the \n",
    "function everywhere, this expression for the derivative is prone to an error known as _subtractive cancellation_.  Subtractive cancellation occurs if you make $h$ very small, as the definition requires. \n",
    "\n",
    "Consider for example the function $f(x) = \\cos(x)\\tanh(x)$. You can verify that it's derivative at $x=2$ is\n",
    "\n",
    "$$\n",
    "\tf'(2) = \\cos(2){\\rm sech}^2(2) - \\sin(2)\\tanh(2) \\approx -0.905989\n",
    "$$\n",
    "\n",
    "However, if we use the definition (1) with $h = 10^{-16}$, the result in double precision is \n",
    "\n",
    "$$\n",
    "\tf'(2) = \\frac{f(2+h) - f(2)}{h} = 0.0\n",
    "$$\n",
    "\n",
    "The answer is wrong because with double precision both $f(2+h)$ and $f(2)$ evaluate to $-0.40117702779274822$.  \n",
    "With single precision, subtractive cancellation occurs for much larger values of $h$. \n",
    "\n",
    "## Why is this? How variables are stored.\n",
    "\n",
    "Computer represent all numbers as strings of bits. For integers, this is straightforward:\n",
    "\n",
    "    1 = 0001\n",
    "    2 = 0010\n",
    "    3 = 0011\n",
    "\n",
    "etc. For floating point numbers (decimals), life is a little bit harder.  To get an idea of how this works, try out this interactive tool:\n",
    "\n",
    "http://evanw.github.io/float-toy/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fMJL2q0xyk5"
   },
   "source": [
    "## Forward and Backward Difference Formulas\n",
    "\n",
    "\n",
    "The definition (1) for the derivative $f'(x)$ requires us to evaluate the function \n",
    "at two points, namely, $x+h$ and $x$. We need to develop techniques to *approximate the derivative $f'(x)$ \n",
    "that do not require us to take the limit $h\\to 0$. The approximations to $f'(x)$ are constructed from \n",
    "combinations of the function $f$ evaluated at various points surrounding $x$. We refer to these as *finite \n",
    "difference* formulas. \n",
    "\n",
    "Let's say we want to approximate $f'(x)$ using the \n",
    "values of $f$ at the points $x$ and $x+h$. That is, we want a formula that says \n",
    "\n",
    "```math\n",
    "f'(x) \\approx a f(x+h) + b f(x) \n",
    "\\tag{2}\n",
    "```\n",
    "\n",
    "for some constants $a$ and $b$. We can determine $a$ and $b$ by using the Taylor series\n",
    "\n",
    "$$\n",
    "\tf(x+h) = f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\cdots\n",
    "$$\n",
    "\n",
    "to expand the right--hand side of Eq.(2). This yields \n",
    "\n",
    "$$\n",
    "\ta f(x+h) + b f(x)  = (a+b)f(x) + a f'(x) h + \\frac{a}{2} f''(x) h^2 + \\cdots\n",
    "\\tag{3}\n",
    "$$\n",
    "\n",
    "The right--hand side of this relation will equal $f'(x)$, approximately, if $a+b=0$ and $a=1/h$. (That is, $a=1/h$ and $b=-1/h$.) \n",
    "With these values for the constants, Eq.(2) yields \n",
    "\n",
    "$$\n",
    "\tf'(x) \\approx \\frac{f(x+h) - f(x)}{h}\n",
    "\\tag{4}\n",
    "$$\n",
    "\n",
    "This approximation to the first derivative is called the _forward difference_. It is simply the \n",
    "definition (1) without the limit $h \\to 0$.\n",
    "\n",
    "Let's look at this result a bit more closely. With $a=1/h$ and $b=-1/h$, Eq.(3)\n",
    "becomes \n",
    "\n",
    "$$\n",
    "\t\\frac{1}{h} f(x+h) - \\frac{1}{h} f(x) = f'(x) + \\frac{1}{2} f''(x) h + \\cdots\n",
    "$$\n",
    "\n",
    "Equivalently, we can write this as\n",
    "\n",
    "$$\n",
    "\tf'(x) = \\frac{f(x+h) - f(x)}{h} - \\frac{1}{2} f''(x) h + \\cdots\n",
    "\\tag{5}\n",
    "$$\n",
    "\n",
    "This shows that the error in the forward difference approximation (5) is\n",
    "\n",
    "$$\n",
    "\t{\\cal E}_F = \\frac{1}{2} f''(x) h + \\cdots\n",
    "$$\n",
    "\n",
    "In particular, the leading term in ${\\cal E}_F$ is proportional to $h$.\n",
    "\n",
    "We can carry out a similar analysis to obtain a finite difference approximation to \n",
    "$f'(x)$ using the points $x-h$ and $x$. \n",
    "The result is the _backward difference_ approximation\n",
    "\n",
    "$$\n",
    "\tf'(x) \\approx \\frac{f(x) - f(x-h)}{h}\n",
    "$$\n",
    "\n",
    "with error \n",
    "$$\n",
    "\t{\\cal E}_B = -\\frac{1}{2} f''(x) h + \\cdots \n",
    "$$\n",
    "\n",
    "Again, the leading term in the error is proportional to $h$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sxNqzsuxyk6"
   },
   "source": [
    "## Exercise 1: \n",
    "\n",
    "Write a code to compute the forward and backward difference approximations to $f'(2.0)$, where \n",
    "$f(x) =  \\cos(x)\\tanh(x)$. Use $h = 10^{-1}, 10^{-2},\\ldots,10^{-7}$. For both approximation methods, show that the errors ${\\cal E}$ are \n",
    "proportional to $h$ in one of two ways:\n",
    "\n",
    "1. Show that a log--log plot of ${\\cal E}$ versus $h$ gives a straight \n",
    "line with slope $1$. \n",
    "\n",
    "2. If the error is proportional to $h$, then ${\\cal E} = C h$ for some constant $C$. \n",
    "Let $h_1$ and $h_2$ denote your two smallest $h$ values, and ${\\cal E}_1$ and ${\\cal E}_2$ denote the corresponding \n",
    "errors. The relations ${\\cal E}_1 = C h_1$ and ${\\cal E}_2 = C h_2$ imply ${\\cal E}_2/{\\cal E}_1 = h_2/h_1$. If the \n",
    "ratio ${\\cal E}_2/{\\cal E}_1$ agrees (approximately) with the ratio $h_2/h_1$, then the errors are proportional to $h$.\n",
    "\n",
    "**New command for today: numpy.zeros_like() -- it produces an array of zeros of the same shape as the one you give it.  So, for 1D arrays, it's equivalent to numpy.zeros(len(A)), where A is your reference array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3gNfD2QVxyk6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0.1 || forward difference = -0.887518521079419 || Error = -0.007614379786265613\n",
      "h = 0.01 || forward difference = -0.904321551646553 || Error = -0.0012865089943149832\n",
      "h = 0.001 || forward difference = -0.9058240206696322 || Error = -0.0001335700170369547\n",
      "h = 0.0001 || forward difference = -0.9059724442250783 || Error = -1.3405852463538315e-05\n",
      "h = 1e-05 || forward difference = -0.9059872683070401 || Error = -1.3410734129304382e-06\n",
      "h = 1e-06 || forward difference = -0.9059887506324138 || Error = -1.3411222268833178e-07\n",
      "h = 1e-07 || forward difference = -0.9059888977924757 || Error = -1.3411271010399517e-08\n",
      "h = 0.1 || backward difference =  -0.9203543413597404 || Error = 0.01844758535633395\n",
      "h = 0.01 || backward difference =  -0.9076152373688418 || Error = 0.001394980652860256\n",
      "h = 0.001 || backward difference =  -0.9061533993448001 || Error = 0.00013465474721560677\n",
      "h = 0.0001 || backward difference =  -0.9060053821008385 || Error = 1.3416699766538587e-05\n",
      "h = 1e-05 || backward difference =  -0.9059905620945051 || Error = 1.3411818859665472e-06\n",
      "h = 1e-06 || backward difference =  -0.9059890798690517 || Error = 1.3411330729296012e-07\n",
      "h = 1e-07 || backward difference =  -0.905988932764501 || Error = 1.3411282057118612e-08\n",
      "h2/h1 = 10.0 || Ef2/Ef1 = 9.99996365626621 || Eb2/Eb1 = 10.000036291964625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return np.cos(x)*np.tanh(x)\n",
    "\n",
    "def fdiff(x, h):\n",
    "    return (f(x + h) - f(x))/h\n",
    "\n",
    "def fError(x, h):\n",
    "    deriv_2 = fdiff(fdiff(x, h), h)\n",
    "    return 0.5*h*deriv_2\n",
    "\n",
    "\n",
    "def bdiff(x, h):\n",
    "     return (f(x) - f(x - h))/h\n",
    "\n",
    "def bError(x, h):\n",
    "    deriv_2 = bdiff(bdiff(x, h), h)\n",
    "    return -0.5*h*deriv_2\n",
    "\n",
    "\n",
    "for i in range (7):\n",
    "    h = 10**(-(i+1))\n",
    "    print('h =', h, '||', 'forward difference =', fdiff(2, h),'||', 'Error =', fError(2, h) )\n",
    "\n",
    "for i in range(7):\n",
    "    h = 10**(-(i+1))\n",
    "    print('h =', h,'||', 'backward difference = ', bdiff(2, h), '||','Error =', bError(2, h) )\n",
    "\n",
    "h1 = 10**(-7)\n",
    "h2 = 10**(-6)\n",
    "\n",
    "Ef1 = fError(2, h1)\n",
    "Ef2 = fError(2, h2)\n",
    "\n",
    "Eb1 = bError(2, h1)\n",
    "Eb2 = bError(2, h2)\n",
    "\n",
    "print('h2/h1 =',h2/h1, '||', 'Ef2/Ef1 =', Ef2/Ef1, '||', 'Eb2/Eb1 =', Eb2/Eb1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqmv_k5Rxyk7"
   },
   "source": [
    "## Machine Error\n",
    "\n",
    "What if we continued this approach of decreasing $h$ below $10^{-7}$ or so?  Try to calculate the derivative for smaller and smaller $h$.  Plot a log-log of the error just like above, but continue below $10^{-7}$ -- what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "bN6lIyFexyk7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_arr = np.zeros(20)\n",
    "err_arr = np.zeros_like(h_arr)\n",
    "for i in range (20):\n",
    "    h = 10**(-(i+1))\n",
    "    #print('h =', h, '||', 'forward difference =', fdiff(2, h),'||', 'Error =', fError(2, h) )\n",
    "\n",
    "for i in range(20):\n",
    "    h = 10**(-(i+1))\n",
    "    #print('h =', h,'||', 'backward difference = ', bdiff(2, h), '||','Error =', bError(2, h) )\n",
    "for i in range(20):\n",
    "    h = 10**(-(i+1))\n",
    "    h_arr[i] = h\n",
    "    err_arr[i] = np.abs(fError(2, h))\n",
    "\n",
    "plt.loglog(h_arr, err_arr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "3Eg46rL_xyk7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30000000000000004\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "#Computers represent numbers in a binary floating point format with a fixed number of bits.  \n",
    "#This means that you have some limitation in how many digits your computer can represent.\n",
    "#For example, try the following:\n",
    "\n",
    "print(0.1+0.2)\n",
    "print(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "AfYXwzlSxyk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and b are different\n"
     ]
    }
   ],
   "source": [
    "# This means that statements you *think* are true sometimes are not:\n",
    "a = 0.1 + 0.2\n",
    "b = 0.3\n",
    "\n",
    "if a==b:\n",
    "    print(\"a and b are the same!\")\n",
    "else:\n",
    "    print(\"a and b are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "m58KXf6hxyk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and b are the same!\n"
     ]
    }
   ],
   "source": [
    "# Aside from the numerical error you saw above in trying to use numbers h that are too small,\n",
    "# the biggest place you'll have to pay attention is in comparisons such as the one above.  The correct\n",
    "# way to do this is by comparing the absolutel value of the difference to a small number: |a - b| < tolerance\n",
    "\n",
    "a = 0.1 + 0.2\n",
    "b = 0.3\n",
    "\n",
    "if abs(a-b) < 1e-10:\n",
    "    print(\"a and b are the same!\")\n",
    "else:\n",
    "    print(\"a and b are different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ilHYN3Qxyk8"
   },
   "source": [
    "You can find some more reading on floating point error here:\n",
    "* http://www.lahey.com/float.htm\n",
    "* https://docs.python.org/3/tutorial/floatingpoint.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyU0i4fsxyk9"
   },
   "source": [
    "## Central Difference Formula\n",
    "\n",
    "Let's derive a finite difference approximation for $f'(x)$ using the _three_ points $x-h$, $x$ and $x+h$. \n",
    "That is, we seek a relation \n",
    "\n",
    "$$\n",
    "\tf'(x) \\approx a f(x-h) + b f(x) + c f(x+h)\n",
    "    \\tag{8}\n",
    "$$\n",
    "\n",
    "for some constants $a$, $b$ and $c$. The contants are determined by expanding $f(x-h)$ and $f(x+h)$ in Taylor series\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\tf(x-h) & = f(x) - f'(x) h + \\frac{1}{2} f''(x) h^2 - \\frac{1}{6} f'''(x) h^3 + \\cdots  \\\\\n",
    "\tf(x+h) & = f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\frac{1}{6} f'''(x) h^3 + \\cdots \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and inserting these into the right--hand side of Eq. (8):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\ta f(x-h) + b f(x) + c f(x+h) & =  (a + b + c)f(x) + (c-a)f'(x) h + \\frac{1}{2}(c+a)f''(x) h^2 \\ \\\\\n",
    "\t&  \\quad + \\frac{1}{6}(c-a)f'''(x) h^3 + \\cdots\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This expression will equal $f'(x)$, approximately, if \n",
    "\n",
    "$$\n",
    "(a+b+c) = 0, \\\\\n",
    "(c-a) = 1/h, \\\\\n",
    "(c+a) = 0. \n",
    "$$\n",
    "\n",
    "That is, $a = -1/(2h)$, $b=0$, and $c=1/(2h)$. With these values for the constants, we have \n",
    "\n",
    "$$\n",
    "\t-\\frac{1}{2h} f(x-h) + \\frac{1}{2h} f(x+h) = f'(x) + \\frac{1}{6} f'''(x) h^2 + \\cdots\n",
    "$$\n",
    "\n",
    "This gives us the __central difference__ formula for the first derivative:\n",
    "\n",
    "$$\n",
    "\tf'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h} \n",
    "$$\n",
    "\n",
    "The error for this method is \n",
    "\n",
    "$$\n",
    "\t{\\cal E}_C = \\frac{1}{6} f'''(x) h^2 + \\cdots\n",
    "$$\n",
    "\n",
    "It is proportional to $h^2$. \n",
    "\n",
    "The central difference formula is simply the average of the forward and \n",
    "backward difference formulas. In taking the average, the order $h$ terms in the errors ${\\cal E}_F$ and ${\\cal E}_B$ \n",
    "cancel. The order $h^2$ terms, included in the $\\cdots$ of Eqs.(6) and (7), do not \n",
    "cancel; rather, they combine to give the central difference error ${\\cal E}_C$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3sq0tjmxyk9"
   },
   "source": [
    "## Homework 3.1\n",
    "\n",
    "Numerically-compute the derivative of $f(x) = \\cos(x)\\tanh(x)$ at $x=2$ using the central difference method. Using a graph, show that the error ${\\cal E}$ is proportional to $h^2$, by comparing to the value you know from calculus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVtW8UR_xyk9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lwlv7t8Pxyk9"
   },
   "source": [
    "Other stencils\n",
    "--------------------\n",
    "The pattern of evaluation points and coefficients is sometimes referred to as the \"stencil\". For example, the forward difference \n",
    "formulae might be called a one-sided, two-point stencil. The central difference formula \n",
    "is a centered, three-point stencil (although the coefficient of one of those points is zero). \n",
    "\n",
    "The method of the preceeding sections can be used to obtain other stencils for $f'(x)$. For example, we might \n",
    "want to calculate the derivative without any function evaluations at points less than $x$. For this we can choose \n",
    "a three-point stencil consisting of the points $x$, $x+h$ and $x+2h$. Using the Taylor series expressions \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\tf(x+h) & = & f(x) + f'(x) h + \\frac{1}{2} f''(x) h^2 + \\frac{1}{6} f'''(x) h^3 + \\cdots \\\\\n",
    "\tf(x+2h) & = & f(x) + 2 f'(x) h + \\frac{4}{2} f''(x) h^2 + \\frac{8}{6} f'''(x) h^3 + \\cdots\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "we have \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\ta f(x) + b f(x+h) + c f(x+2h) & =   (a + b + c) f(x) + (b + 2c) f'(x) h \\\\\n",
    "\t & + \\frac{1}{2} (b + 4c) f''(x) h^2  + \\frac{1}{6} (b + 8c) f'''(x) h^3 + \\cdots\n",
    "\\end{aligned}\n",
    "\\tag{9}   \n",
    "$$\n",
    "\n",
    "This will approximate $f'(x)$ if the coefficients satisfy\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(a + b + c) & = & 0 \\\\\n",
    "\t(b + 2c)h & = & 1 \\\\\n",
    "\t(b + 4c) & = & 0 \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The solution is $a = -3/(2h)$, $b = 2/h$, $c = -1/(2h)$. This yields the finite difference formula\n",
    "\n",
    "$$\n",
    "f'(x) \\approx \\frac{-3f(x) + 4f(x+h) - f(x+2h)}{2h}\n",
    "\\tag{10}\n",
    "$$\n",
    "\n",
    "The terms $(b+8c)f'''(x) h^3/6 + \\cdots$ from Eq.(9), which are order $h^2$, do not vanish. Thus, the error \n",
    "for this one-sided, three-point stencil is proportional to $h^2$. \n",
    "\n",
    "You should write this out for yourselves on a whiteboard in class, so you can see how the steps work. Once you get to solving the system of 3 equations, consider trying Wolfram Alpha, using [this example](https://www.wolframalpha.com/input?i=solve+x+%2B+y+%3D+7+and+2x+%3D+12) as guidance.\n",
    "\n",
    "In general, derivative formulas that use large stencils have higher order error. (That is, the error is a higher \n",
    "power of $h$.) However, derivative formulas with large stencils are more susceptible to subtractive cancellation errors.  Thus, a stencil with a very high order error is not necessarily better to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEpEgCx2xyk9"
   },
   "source": [
    "## Homework 3.2\n",
    "\n",
    "First, make sure that you understand the three-point stencil derivation, above. If you get stuck on this problem, you can use the three-point stencil (first) and then come back later to update your answer to use a five-point stencil as a do-over.\n",
    "\n",
    "a) Determine the five-point centered stencil for $f'(x)$: this stencil is like the three-point stencil in Eq. 10, but spans the points $x-2h$, $x-h$, $x$, $x+h$, $x+2h$. You may use Mathematica or Maple to solve for the constants yourself (excellent!), or ask for help to get them. Write your equations in a similar form to the three-point stencil above. \n",
    "\n",
    "b) Numerically-compute the derivative of $f(x) = \\cos(x)\\tanh(x)$ at $x=2$ using this five-point stencil. Using a graph, show that the error ${\\cal E}$ is proportional to $h^4$, by comparing to the value you know from calculus. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rh-Jn2NSxyk9"
   },
   "source": [
    "### Solution to part (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can write equations as if they were $\\LaTeX$, such as $f(x) = x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution to part (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFg8vR1Jxyk-"
   },
   "source": [
    "## Second derivatives\n",
    "\n",
    "We can apply the same technique to derive finite difference stencils for second derivatives, $f''(x)$, as well as higher order \n",
    "derivatives. For example, consider the three-point centered stencil for $f''(x)$. We can derive this stencil by\n",
    "examining the Taylor expansion:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\ta f(x-h) + b f(x) + c f(x+h) & =  (a + b + c)f(x) + (c-a)f'(x) h + \\frac{1}{2}(c+a)f''(x) h^2  \\\\\n",
    "\t&  \\quad + \\frac{1}{6}(c-a)f'''(x) h^3 + \\cdots\n",
    "\\end{aligned}\n",
    "    \\tag{11}\n",
    "$$\n",
    "\n",
    "The right-hand side will approximate $f''(x)$ if $(a+b+c)=0$, $(c-a)=0$ and $(c+a) h^2/2 = 1$. This gives \n",
    "$a = 1/h^2$, $b = -2/h^2$ and $c = 1/h^2$, so that\n",
    "\n",
    "$$\n",
    "\t\\frac{1}{h^2} f(x-h) - \\frac{2}{h^2} f(x) + \\frac{1}{h^2} f(x+h) = f''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Thus, the centered three-point stencil for the second derivative is \n",
    "\n",
    "$$\n",
    "\tf''(x) \\approx \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}\n",
    "    \\tag{12}\n",
    "$$\n",
    "\n",
    "Note that the term $(c-a)f'''(x) h^3/6$ in Eq.(11) vanishes for the chosen values of \n",
    "$a$, $b$ and $c$. The next order term in Eq.(11) is proportional to $(c+a) f''''(x) h^4$. This term does not vanish and is proportional to $h^2$. Thus, the error for the formula (12) is of order $h^2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-yPV-VIxyk-"
   },
   "source": [
    "## Homework 3.3: \n",
    "\n",
    "a) Numerically-compute the second derivative of $f(x) = \\ln(x)/\\cosh(x)$ for $2.0 \\le x \\le 5.0$, using the three-point centered stencil (Eq. 12). Plot a graph of $f''(x)$ over this range. \n",
    "\n",
    "b) Consider this graph: what features (limits? max? min? other comparisons?) can you explain using mathematics, that give you confidence in your result?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmsbwxiYd6YX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf5mWF_Wxyk-"
   },
   "source": [
    "# Post-class\n",
    "\n",
    "If you didn't complete HW 3.2a (derivation of 5-point stencil) during class, then please ask for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hf2gLDxkxyk-"
   },
   "source": [
    "\n",
    "# Homework 3\n",
    "\n",
    "The problems listed here are the entirety of Project 3, and will be turned in as a ipynb on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKrWrzHjxyk-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Module 4 Numerical Differentiation and Machine Error.ipynb",
   "provenance": {
    "Author": "Karen Daniels",
    "Course": "NCSU-PY251"
   }
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
